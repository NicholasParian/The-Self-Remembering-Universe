# The Self-Remembering Universe

This repository contains all formal materials, source files, diagrams, derivations, and simulations related to the ongoing research program titled **The Self-Remembering Universe** ‚Äî a recursive cosmological framework built across three foundational papers:

## Papers

I - **The Self-Remembering Universe I** *(draft)*  
   *Quantum Coherence Through Cyclic Spacetime Einstein‚ÄìRosen Bridges*  
   Defines a cyclic quantum cosmology grounded in loop quantum gravity, ER=EPR, and recursive entanglement structure.

II - **The Self-Remembering Universe II** *(in development)*  
   *Recursive Optimization and Coherence Mechanics in Meta-Configurational Dynamics*  
   Introduces the MetaCube: a computational structure modeling recursive evolution, memory retention, and attractor convergence through a cost-based learning functional.

III - **The Self-Remembering Universe III** *(planned)*  
   *Emergent Purpose, Observer Embedding, and the Logic of Existence*  
   Addresses the ‚Äúwhy‚Äù of cosmological existence from within a memory-bearing, coherence-optimizing framework.


## Status

- ‚úÖ Paper I: finalized draft
- üîÑ Paper II: in active development
- ‚è≥ Paper III: conceptually outlined

## License

All code, documents, and materials are released under the MIT License unless otherwise stated. See [LICENSE](./LICENSE) for details.

---

## Contact

**Nicholas Parian**  
Lead Author and Architect of the Recursive Coherence Framework  

## Disclosures
Portions of this manuscript‚Äîincluding the development, refinement, formatting of mathematical expressions, narrative structure, and citation management‚Äîwere produced in collaboration with OpenAI's GPT-4 model (ChatGPT), Google's Gemini 2.0, and DeepSeek R1. The human author, Nicholas Parian, guided the conceptual framework, directed the line of inquiry, posed the core hypotheses, and curated the final scientific content.

The use of artificial intelligence was instrumental in accelerating the writing, organizing technical arguments, and cross-referencing related literature. However, all original theoretical contributions, interpretations, and decisions regarding inclusion, emphasis, and framing were made by the human author.

This disclosure is provided in the interest of transparency and to acknowledge the evolving role of large language models in academic research and writing. The author assumes full responsibility for the accuracy, novelty, and scientific validity of the material presented.



